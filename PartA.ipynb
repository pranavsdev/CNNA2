{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PartA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCR6tpG9abXX",
        "colab_type": "code",
        "outputId": "eb27ee7a-25c0-44bb-c279-b80fef2bd5e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive \n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRZYQKGUamhp",
        "colab_type": "code",
        "outputId": "f3c9bae7-9a58-480b-81b5-4c30361f23dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!unzip \"/content/gdrive/My Drive/Colab Notebooks/data.h5.zip\" -d \"./\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/gdrive/My Drive/Colab Notebooks/data.h5.zip\n",
            "  inflating: ./data1.h5              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZSBojnwbUZX",
        "colab_type": "code",
        "outputId": "e3590fc6-451d-4339-e125-8bfdbc7922d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 958
        }
      },
      "source": [
        "\"\"\"\n",
        "Author: Pranav Srivastava\n",
        "file: PartA.py\n",
        "This file has implementation of PartA (i) and (ii)\n",
        "\n",
        "execution: functions compile_and_train and fetch_and_test_CNNensemble can be used to execute the solutions. Please check the deatils at the bottom of this file\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import h5py\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os\n",
        "from contextlib import redirect_stdout\n",
        "\n",
        "def loadDataH5():\n",
        "    with h5py.File('data1.h5','r') as hf:\n",
        "        trainX = np.array(hf.get('trainX'))\n",
        "        trainY = np.array(hf.get('trainY'))\n",
        "        valX = np.array(hf.get('valX'))\n",
        "        valY = np.array(hf.get('valY'))\n",
        "        print (trainX.shape,trainY.shape)\n",
        "        print (valX.shape,valY.shape)\n",
        "    return trainX, trainY, valX, valY\n",
        "\n",
        "trainX, trainY, testX, testY = loadDataH5()\n",
        "\n",
        "def plotAccLoss(H, NUM_EPOCHS, path, description):\n",
        "\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(np.arange(0, NUM_EPOCHS), H.history[\"loss\"], label=\"train_loss\")\n",
        "    plt.plot(np.arange(0, NUM_EPOCHS), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.plot(np.arange(0, NUM_EPOCHS), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "    plt.plot(np.arange(0, NUM_EPOCHS), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "    plt.title(\"Training Loss and Accuracy\")\n",
        "    plt.xlabel(\"Epoch #\")\n",
        "    plt.ylabel(\"Loss/Accuracy\")\n",
        "    plt.legend(['train_loss', 'val_loss', 'train_acc', 'val_acc'], loc='upper right')\n",
        "\n",
        "\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "    plt.savefig(path+description)\n",
        "\n",
        "\n",
        "def save_model_summary(path, cnn_modelname, model, description):\n",
        "    \"\"\"\n",
        "    this function will save the summary of model to the disk\n",
        "    results become handy when preparing the report\n",
        "    \"\"\"\n",
        "\n",
        "    filename = path+\"model_summary\"+\"_\"+cnn_modelname+'_'+description+\".txt\"\n",
        "\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "        with redirect_stdout(f):\n",
        "            model.summary()\n",
        "\n",
        "def save_execution_summary(path, cnn_modelname, model, testdata, testlabels, description):\n",
        "    \"\"\"\n",
        "    this function will save the execution summary to the disk\n",
        "    results become handy when preparing the report\n",
        "    \"\"\"\n",
        "    filename = path+\"model_evaluate\"+\"_\"+cnn_modelname+'_'+description+\".txt\"\n",
        "\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "        with redirect_stdout(f):\n",
        "            model.evaluate(testdata,testlabels)\n",
        "\n",
        "def baselineCNN(width, height, depth, classes):\n",
        "    \"\"\"Implementation of baseline CNN with single convolutional layer, \n",
        "    single pooling layer, fully connected layer and softmax layer.\n",
        "    \"\"\"\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    inputShape= (height, width, depth)\n",
        "\n",
        "    # define the first layer\n",
        "    model.add(tf.keras.layers.Conv2D (64, (3, 3), padding=\"same\",input_shape=inputShape, activation='relu'))\n",
        "\n",
        "    #pooling layer\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "    \n",
        "    #flatten the results\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "    #feed the flattened results into full connected layers\n",
        "    model.add(tf.keras.layers.Dense(500, activation='relu'))\n",
        "\n",
        "    #softmax classifier\n",
        "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "def CNN_Model_1(width, height, depth, classes):\n",
        "    \"\"\"CNN Model 1\"\"\"\n",
        "\n",
        "    inputShape = (width, height, depth)\n",
        "    model = tf.keras.models.Sequential()\n",
        "    \n",
        "    # define the first convolutional layer\n",
        "    model.add(tf.keras.layers.Conv2D (64, (3, 3), padding=\"same\",input_shape=inputShape, activation='relu'))\n",
        "\n",
        "    #pooling layer\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    #second convolutional layer\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "    \n",
        "    #pooling layer\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    \n",
        "    #flatten the results\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "    #feed the flattened results into full connected layers\n",
        "    model.add(tf.keras.layers.Dense(500, activation='relu'))\n",
        "\n",
        "    #softmax classifier\n",
        "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "def CNN_Model_2(width, height, depth, classes):\n",
        "    \"\"\"CNN Model 2\"\"\"\n",
        "\n",
        "    inputShape = (width, height, depth)\n",
        "    model = tf.keras.models.Sequential()\n",
        "    \n",
        "    #first convolutional layer\n",
        "    model.add(tf.keras.layers.Conv2D (64, (3, 3), padding=\"same\",input_shape=inputShape, activation='relu'))\n",
        "\n",
        "    #first pooling layer\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    #second convolutional layer\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "    \n",
        "    #second pooling layer\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    \n",
        "    #third convolutional layer\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "    \n",
        "    #third pooling layer\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    #flatten the results\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "    #feed the flattened results into full connected layers\n",
        "    model.add(tf.keras.layers.Dense(500, activation='relu'))\n",
        "\n",
        "    #apply dropout\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "    #softmax classifier\n",
        "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "def CNN_Model_3(width, height, depth, classes):\n",
        "    \"\"\"CNN Model 3\"\"\"\n",
        "\n",
        "    inputShape = (width, height, depth)\n",
        "    model = tf.keras.models.Sequential()\n",
        "    \n",
        "    #first convolutional layer\n",
        "    model.add(tf.keras.layers.Conv2D (64, (3, 3), padding=\"same\",input_shape=inputShape, activation='relu'))\n",
        "\n",
        "    #second convolutional layer\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "    #first pooling layer\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    #third convolutional layer\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "    #fourth convolutional layer\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "    \n",
        "    #second pooling layer\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    #flatten the results\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "    #feed the flattened results into full connected layers\n",
        "    model.add(tf.keras.layers.Dense(1000, activation='relu'))\n",
        "\n",
        "    #apply dropout\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "    #softmax classifier\n",
        "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "def CNN_Model_4(width, height, depth, classes):\n",
        "    \"\"\"CNN Model 4\"\"\"\n",
        "\n",
        "    inputShape = (width, height, depth)\n",
        "    model = tf.keras.models.Sequential()\n",
        "    \n",
        "    model.add(tf.keras.layers.Conv2D (64, (3, 3), padding=\"same\",input_shape=inputShape, activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu')) \n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(1000, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "def CNN_Model_5(width, height, depth, classes):\n",
        "    \"\"\"CNN Model 5\"\"\"\n",
        "\n",
        "    inputShape = (width, height, depth)\n",
        "    model = tf.keras.models.Sequential()\n",
        "    \n",
        "    model.add(tf.keras.layers.Conv2D (64, (3, 3), padding=\"same\",input_shape=inputShape, activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    \n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(1000, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "def CNN_Model_5(width, height, depth, classes):\n",
        "    \"\"\"CNN Model 5\"\"\"\n",
        "\n",
        "    inputShape = (width, height, depth)\n",
        "    model = tf.keras.models.Sequential()\n",
        "    \n",
        "    model.add(tf.keras.layers.Conv2D (64, (3, 3), padding=\"same\",input_shape=inputShape, activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(1000, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "def CNN_Model_6(width, height, depth, classes):\n",
        "    \"\"\"CNN Model 6\"\"\"\n",
        "\n",
        "    inputShape = (width, height, depth)\n",
        "    model = tf.keras.models.Sequential()\n",
        "    \n",
        "    model.add(tf.keras.layers.Conv2D (64, (3, 3), strides=(2, 2),input_shape=inputShape, activation='relu'))\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), activation='relu'))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))    \n",
        "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(1000, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "def CNN_Model_7(width, height, depth, classes):\n",
        "    \"\"\"CNN Model 7\"\"\"\n",
        "\n",
        "    inputShape = (width, height, depth)\n",
        "    model = tf.keras.models.Sequential()\n",
        "    \n",
        "    model.add(tf.keras.layers.Conv2D (32, (3, 3), padding=\"same\",input_shape=inputShape, activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(64, (5, 5), activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(500, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "def CNN_Model_8(width, height, depth, classes):\n",
        "    \"\"\"CNN Model 8\"\"\"\n",
        "\n",
        "    inputShape = (width, height, depth)\n",
        "    model = tf.keras.models.Sequential()\n",
        "    \n",
        "    model.add(tf.keras.layers.Conv2D (16, (3, 3), padding=\"same\",input_shape=inputShape, activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(64, (5, 5), padding=\"same\", activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "    \n",
        "    model.add(tf.keras.layers.Conv2D(128, (7, 7), activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(500, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "def CNN_Model_9(width, height, depth, classes):\n",
        "    \"\"\"CNN Model 9\"\"\"\n",
        "\n",
        "    inputShape = (width, height, depth)\n",
        "    model = tf.keras.models.Sequential()\n",
        "    \n",
        "    model.add(tf.keras.layers.Conv2D (16, (3, 3), padding=\"same\",input_shape=inputShape, activation='relu'))\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(500, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "def CNN_Model_10(width, height, depth, classes):\n",
        "    \"\"\"CNN Model 10\"\"\"\n",
        "\n",
        "    inputShape = (width, height, depth)\n",
        "    model = tf.keras.models.Sequential()\n",
        "    \n",
        "    model.add(tf.keras.layers.Conv2D (16, (3, 3), padding=\"same\",input_shape=inputShape, activation='relu'))\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(500, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "def CNN_Model_11(width, height, depth, classes):\n",
        "    \"\"\"CNN Model 11 with 1x1 convolutional filter\"\"\"\n",
        "\n",
        "    inputShape = (width, height, depth)\n",
        "    model = tf.keras.models.Sequential()\n",
        "    \n",
        "    model.add(tf.keras.layers.Conv2D (64, (3, 3), padding=\"same\",input_shape=inputShape, activation='relu'))\n",
        "    model.add(tf.keras.layers.Conv2D(64, (1,1), activation='relu'))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(tf.keras.layers.Conv2D(64, (1,1), activation='relu'))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(500, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "def compile_and_train(models_dict, batch_size, learning_rate, NUM_EPOCHS, execution_summary):\n",
        "    \"\"\"\n",
        "    - this function is used in both (i) and (ii) of Part A\n",
        "\n",
        "    - this function is used to compile and train the model\n",
        "    \n",
        "    - it acts a trigger when training of various model with variations are to be triggered with some automation\n",
        "\n",
        "    - model_dict is a very important param in this funtion which is a dictionary of models that are required to be compiled along with the check if the data-augmentation or checkpoint should be applied in the training\n",
        "    \n",
        "    \"\"\"\n",
        "    # initialize the optimizer and model\n",
        "    print(\"Compiling model...\")\n",
        "    opt = keras.optimizers.SGD(lr=learning_rate)\n",
        "\n",
        "    numTrainingSamples = 1020\n",
        "    numValidationSamples = 340\n",
        "\n",
        "    # iterate till all the modelsin the list are compiled and trained\n",
        "    for key in models_dict:\n",
        "        checkpoint=False\n",
        "        data_augmentation=False\n",
        "\n",
        "        result_path=\"/content/gdrive/My Drive/Colab Notebooks/Executions/\"+key+\"/\"\n",
        "        cp_path=\"/content/gdrive/My Drive/Colab Notebooks/Checkpoints/\"+key+\"/\"\n",
        "\n",
        "        if not os.path.exists(result_path):\n",
        "            os.makedirs(result_path)\n",
        "\n",
        "        if not os.path.exists(cp_path):\n",
        "            os.makedirs(cp_path)\n",
        "        \n",
        "        print(\"key is \", key)\n",
        "        model = models_dict[key][0](width=128, height=128, depth=3, classes=17)\n",
        "\n",
        "        #condition to check if the model should have a checkpoint or data-augmentation option\n",
        "        if models_dict[key][1] == True and models_dict[key][2] == False:\n",
        "            checkpoint = True\n",
        "\n",
        "        if models_dict[key][2] == True and models_dict[key][1] == False:\n",
        "            data_augmentation = True\n",
        "\n",
        "        if models_dict[key][1] == True and models_dict[key][2] == True:\n",
        "            checkpoint = True\n",
        "            data_augmentation = True\n",
        "\n",
        "\n",
        "        print(model.summary())\n",
        "        save_model_summary(path=result_path, cnn_modelname=key, model=model, description=execution_summary)\n",
        "\n",
        "        model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\n",
        "\n",
        "        #execute the variants based on the choice specified\n",
        "        if checkpoint==True and data_augmentation==False:\n",
        "            fname = cp_path+key+\"_\"+execution_summary+\".hdf5\"\n",
        "            checkpoint = tf.keras.callbacks.ModelCheckpoint(fname, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)\n",
        "\n",
        "            #trainthenetwork\n",
        "            print(\"Trainingnetwork...\")\n",
        "            history=model.fit(trainX,trainY,validation_data=(testX,testY),batch_size=batch_size,epochs=NUM_EPOCHS, callbacks=[checkpoint])\n",
        "\n",
        "        if checkpoint==False and data_augmentation==True:\n",
        "            #initialize data generator with various parameters\n",
        "            trainDataGenerator= tf.keras.preprocessing.image.ImageDataGenerator( rotation_range=90, height_shift_range=0.5, width_shift_range=0.3, shear_range=0.2, zoom_range=[0.4,0.9], horizontal_flip=True)\n",
        "            testDataGenerator= tf.keras.preprocessing.image.ImageDataGenerator( rotation_range=90, height_shift_range=0.5, width_shift_range=0.3, shear_range=0.2, zoom_range=[0.4,0.9], horizontal_flip=True)\n",
        "\n",
        "            #assign train, test data to data generator along with the labels\n",
        "            train_generator = trainDataGenerator.flow(trainX, trainY, batch_size)\n",
        "            validation_generator = testDataGenerator.flow(testX, testY, batch_size)\n",
        "        \n",
        "            #fit the model on real time data-augmentation\n",
        "            history = model.fit(\n",
        "                train_generator,\n",
        "                steps_per_epoch= numTrainingSamples / batch_size,\n",
        "                epochs=NUM_EPOCHS,\n",
        "                validation_data=validation_generator,\n",
        "                validation_steps=numValidationSamples / batch_size)\n",
        "\n",
        "\n",
        "        if checkpoint==True and data_augmentation==True:\n",
        "            fname = cp_path+key+\"_\"+execution_summary+\".hdf5\"\n",
        "            checkpoint = tf.keras.callbacks.ModelCheckpoint(fname, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)\n",
        "\n",
        "            #initialize data generator with various parameters\n",
        "            trainDataGenerator= tf.keras.preprocessing.image.ImageDataGenerator( rotation_range=90, height_shift_range=0.5, width_shift_range=0.3, shear_range=0.2, zoom_range=[0.4,0.9], horizontal_flip=True)\n",
        "            testDataGenerator= tf.keras.preprocessing.image.ImageDataGenerator( rotation_range=90, height_shift_range=0.5, width_shift_range=0.3, shear_range=0.2, zoom_range=[0.4,0.9], horizontal_flip=True)\n",
        "\n",
        "            #assign train, test data to data generator along with the labels\n",
        "            train_generator = trainDataGenerator.flow(trainX, trainY, batch_size)\n",
        "            validation_generator = testDataGenerator.flow(testX, testY, batch_size)\n",
        "        \n",
        "            #fit the model on real time data-augmentation\n",
        "            history = model.fit(\n",
        "                train_generator,\n",
        "                steps_per_epoch= numTrainingSamples / batch_size,\n",
        "                epochs=NUM_EPOCHS,\n",
        "                validation_data=validation_generator,\n",
        "                validation_steps=numValidationSamples / batch_size,\n",
        "                callbacks=[checkpoint])\n",
        "        \n",
        "\n",
        "        if checkpoint==False and data_augmentation==False:\n",
        "            #trainthenetwork\n",
        "            print(\"Trainingnetwork...\")\n",
        "            history=model.fit(trainX,trainY,validation_data=(testX,testY),batch_size=batch_size,epochs=NUM_EPOCHS)\n",
        "            \n",
        "            #exe_graph_name_loc = \"Executions/\"+key+\"/\"+key+\"_\"+execution_summary+\".png\"\n",
        "        \n",
        "        #evaluate the test accuracy\n",
        "        print (\"Test Data Loss and Accuracy: \", model.evaluate(testX, testY))        \n",
        "        save_execution_summary(path=result_path, cnn_modelname=key, model=model, testdata=testX, testlabels=testY, description=execution_summary)\n",
        "\n",
        "        #plot and save the results in the graph\n",
        "        graph_description = key+\"_\"+execution_summary+\".png\"        \n",
        "        plotAccLoss(H=history, NUM_EPOCHS=NUM_EPOCHS, path=result_path, description=graph_description)\n",
        "\n",
        "\n",
        "def fetch_and_test_CNNensemble():\n",
        "    \"\"\"\n",
        "    This fucntion is imoplemeted for Part A (ii)\n",
        "\n",
        "    It is used to fetch the weights for the trained models and later apply CNN ensemble   \n",
        "    \"\"\"\n",
        "\n",
        "    models = []\n",
        "\n",
        "    #this is the dictionary that specifies which all trained models will be used for CNN ensemble\n",
        "    ensemble_models = models_dict = {\n",
        "    'CNN_Model_1':CNN_Model_1,\n",
        "    'CNN_Model_2':CNN_Model_2, \n",
        "    'CNN_Model_3':CNN_Model_3,\n",
        "    'CNN_Model_4':CNN_Model_4, \n",
        "    'CNN_Model_5':CNN_Model_5, \n",
        "    'CNN_Model_6':CNN_Model_6, \n",
        "    'CNN_Model_11':CNN_Model_11,\n",
        "    'CNN_Model_8':CNN_Model_8,\n",
        "    'CNN_Model_9':CNN_Model_9, \n",
        "    'CNN_Model_10':CNN_Model_10\n",
        "    }\n",
        "    for key in ensemble_models:\n",
        "        print(\"key is \", key)\n",
        "        #model = baselineCNN(width=128, height=128, depth=3, classes=17)\n",
        "        model = ensemble_models[key](width=128, height=128, depth=3, classes=17)\n",
        "        \n",
        "        fname = \"Checkpoints/\"+key+\"/\"+key+\"_base_learners_with_checkpoint\"+\".hdf5\"\n",
        "        model.load_weights(fname)\n",
        "        opt = keras.optimizers.SGD(lr=0.01)\n",
        "        model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\n",
        "        models.append(model)\n",
        "    \n",
        "    print(\"models-->\", models)\n",
        "    #outputs = [model.outputs[0] for model in models]\n",
        "    pred = keras.layers.Average()([model.predict_proba(testX) for model in models])\n",
        "    print(\"pred avg---\",pred)\n",
        "    pred = tf.math.argmax(pred, axis = -1)\n",
        "    print(\"384 predictions--->\", pred)\n",
        "\n",
        "    print(\"labels-->\", testY.shape)\n",
        "    \n",
        "    equality = tf.equal(pred, testY)\n",
        "    reduce_t = tf.reduce_all(equality)\n",
        "    print(equality)\n",
        "\n",
        "    count = (tf.reduce_sum(tf.cast(equality,tf.float32)))\n",
        "    print(count)\n",
        "    print(\"ensemble accuracy-->\",tf.math.divide(count, testY.shape)[0])\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "#                        execution details below\n",
        "###############################################################################\n",
        "\n",
        "\"\"\"\n",
        "please create folders 'Executions' and 'Checkpoints' as the results will be stored there\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"model_dict is a dictionary of CNN models that are required to be compiled.\n",
        "It also has a flag to check if the data-augmentation or checkpoint \n",
        "should be applied in the training\n",
        "\n",
        "for example - [CNN_Model_1, checkpoint=True, data-augmentation=True] means CNN_Model_1 model should be trained with checkpoint and data augmentation\n",
        "\"\"\"\n",
        "\n",
        "models_dict = {\n",
        "'CNN_Model_1':[CNN_Model_1, True, True]\n",
        "}\n",
        "\n",
        "execution_summary = \"base_learners_with_checkpoint\"\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"below method can be called to train the network. Please check the function parameters and models_dict for appropriate values\"\"\"\n",
        "#compile_and_train(models_dict=models_dict, batch_size=32, learning_rate=0.01, NUM_EPOCHS=100, execution_summary=execution_summary)\n",
        "\n",
        "\"\"\"below method is used for CNN ensemble\"\"\"\n",
        "#fetch_and_test_CNNensemble()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1020, 128, 128, 3) (1020,)\n",
            "(340, 128, 128, 3) (340,)\n",
            "Compiling model...\n",
            "key is  CNN_Model_1\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 128, 128, 64)      1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 62, 62, 32)        18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30752)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 500)               15376500  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 17)                8517      \n",
            "=================================================================\n",
            "Total params: 15,405,273\n",
            "Trainable params: 15,405,273\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/2\n",
            "32/31 [==============================] - ETA: 0s - loss: 2.8169 - accuracy: 0.0725\n",
            "Epoch 00001: val_loss improved from inf to 2.78359, saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/CNN_Model_1/CNN_Model_1_base_learners_with_checkpoint.hdf5\n",
            "32/31 [==============================] - 37s 1s/step - loss: 2.8169 - accuracy: 0.0725 - val_loss: 2.7836 - val_accuracy: 0.1059\n",
            "Epoch 2/2\n",
            "32/31 [==============================] - ETA: 0s - loss: 2.7526 - accuracy: 0.1000\n",
            "Epoch 00002: val_loss improved from 2.78359 to 2.70824, saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/CNN_Model_1/CNN_Model_1_base_learners_with_checkpoint.hdf5\n",
            "32/31 [==============================] - 37s 1s/step - loss: 2.7526 - accuracy: 0.1000 - val_loss: 2.7082 - val_accuracy: 0.1029\n",
            "11/11 [==============================] - 2s 224ms/step - loss: 2.6765 - accuracy: 0.1206\n",
            "Test Data Loss and Accuracy:  [2.6765456199645996, 0.12058823555707932]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'below method is used for CNN ensemble'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}